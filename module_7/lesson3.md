# Урок 3. Градиентный спуск и SGD

В прошлых уроках мы разобрались как находить производную и с ее помощью считать максимумы и минимумы функций. Эти способы прекрасно подходят, когда функцию можно записать на листочек и там же решить задачу, однако часто функции бывают очень сложными и нам бы хотелось научить компьютер решать эти задачи. Один из алгоритмов поиска минимума (или еще говорят **оптимизации функции**) - градиентный спуск.  Важным допущением для работы алгоритма является дифференцируемость функции. Функция для подсчета ошибки, которую мы рассматривали, дифференцируема и с ней нет проблем, но так будет не всегда, поэтому надо помнить об этом.

Давайте разбираться как работает градиентный спуск.

## Как это работает

Мы уже знаем, что для любой функции можно посчитать градиент. В частности, его можно посчитать на компьютере, если взять $\Delta x$ достаточно маленьким и применив несколько хитростей для большей точности.

Самое сложное в оптимизации - решение систем уравнений в общем виде, поэтому давайте уйдем от этого шага. Вместо этого вернемся к геометрической интепретации. Градиент - вектор наискорейшего увеличения функции. Если мы хотим найти минимум, то мы можем сделать шаг в обратном направлении:

$$x_{new} = x_{old} - \nabla f(x_{old})$$

В зависимости от того, насколько велико значение градиента (а оно может быть очень велико), мы можем сделать слишком большой шаг. Давайте добавим параметр $\lambda$, который назовем **скорость обучения (learning rate)** и с его помощью будем регулировать длину вектора градиента:

$$x_{new} = x_{old} - \lambda \nabla f(x_{old})$$

Совершив один такой шаг мы приблизимся к ответу, но нет гарантий, что в этой точке значения градиента будут равны нулю (или близки к нулю). Поэтому давайте сделаем много таких шагов. Формулу для $i$-го шага можно записать так:

$$x_{i + 1} = x_{i} - \lambda \nabla f(x_{i})$$

Проделав нужное количество шагов мы придем к нужной точке.

## Критерий останова

Следующий шаг, с которым нужно разобраться - когда останавливать алгоритм? Мы можем сделать сто шагов, а можем миллион. Как выбрать конечную точку?

Обычно для этого смотрят на длину вектора градиента (еще ее называют **нормой**). До старта алгоритма можно выбрать маленький параметр $\varepsilon$ и после каждого шага сверять норму градиента с этим параметром. Если значения в векторе градиента достаточно маленькие (близки к нулю), то мы можем остановиться, а если нет, то нужно сделать еще какое-то количество итераций:

$$||\nabla f|| < \varepsilon$$

Тут есть проблема, связанная с тем, что алгоритм может расходиться, то есть это условие не выполнится никогда и алгоритм уйдет в бесконечный цикл. Поэтому важно всегда устанавливать максимальное количество шагов. Если алгоритм не достигает экстремума за это количество шагов, то мы выходим из алгоритма и говорим, что нам не удалось достигнуть сходимости.

Существует несколько различных критериев, по которым можно останавливать алгоритм. Можно измерять изменение самое функции и сравнивать их с $\varepsilon$:

$$f(x_{i - 1}) - f(x_i) < \varepsilon$$

Также мы можем знать требуемое значение функции $\hat{y}$, и сравнивать с ним:

$$f(x_i) < \hat{y}$$

## Пример кода градиентного спуска

Дана функция $x^2 + y^2 - 2x + 3y - 25$, нужно найти ее минимум.

Для этой функции мы можем вычислить градиент:

$$\nabla f = (2x - 2, 2y + 3)$$

И напишем код, который реализует градиентный спуск

```python
def f(x, y):
    return x * x + y * y - 2 * x + 3 * y - 25

def grad_f(x, y):
    grad_x = 2 * x - 2
    grad_y = 2 * y + 3
    return np.array([grad_x, grad_y])

x0 = np.array([15, 10])
x_old = x0
# Эти параметры можно менять и смотреть на результат
eps = 10e-6
learning_rate = 0.1
max_steps = 100

i = 0
while np.linalg.norm(grad_f(x_old[0], x_old[1])) > eps:
    # Обновляем x
    x_new = x_old - learning_rate * grad_f(x_old[0], x_old[1])
    x_old = x_new
    
    # Увеличиваем счетчик
    i += 1
    # Проверяем, нужно ли выходить из цикла
    if i == max_steps:
        break

print(x_new, f(x_new[0], x_new[1]), i) 
# [ 1.0000036  -1.49999704] -28.2499999999783 68
```

Алгоритм завершился после 68 итераций, точка минимума $(1, -1.5)$, погрешность начинается с 6 знака после запятой, что и закладывалось в `eps`. Если решить эту задачу аналитически (решая систему уравнений), то получим тот же результат.

Попробуйте поменять параметры - например, можно поставить меньше learning rate (скажем, 0.001) и проверить сколько шагов потребуется для завершения алгоритма.

Также можно выбрать другое `eps` и посмотреть как это отразится на количестве шагов.

## Выбор learning rate

Если мы возьмем слишком большой learning rate, то мы можем просто не прийти в минимум. Точки между шагами будут слишком далеко друг от друга расположены. Представьте, что вы можете только совершать шаг длиной 1000, а минимум находится в точке 4.325. Скорее всего, вы никогда не наступите именно в эту точку. Это можно сравнить со следующей ситуацией - вы идете в аэропорт, садитесь на случайный самолет, который летит в нужном вам направлении, но на неизвестную длину. Хотели из Санкт-Петербурга попасть в Москву, а попали в Индию.

Что ж, раз нельзя выбрать большой learning rate, давайте выбирать его очень маленьким. Это будет больше похоже на пешее путешествие, где после каждого шага вы будете у себя спрашивать, пришли ли вы в нужное место.

Как же тогда поступить? Примерно также как и в реальной жизни. Если вам нужно из Санкт-Петербурга попасть на Красную Площадь, то вы сначала сядете в самолет, затем пересядете на наземный транспорт и в конце дойдете пешком.

Можно learning rate каждые несколько шагов, и сначала большими шагами максимально сблизиться с минимумом, а затем более мелкими шагами попасть в нужную точку.

Существует несколько формул для уменьшения шага. Можно задать шаг вручную (например, первые 30 шагов 0.01, а затем 0.0001). Можно на каждом шаге равномерно уменьшать значение (например, делить на 2), или воспользоваться экспоненциальным сглаживанием. Мы вернемся к этому вопросу на практике, когда будем обучать нейронные сети.

Попробуйте добавить в код выше изменение learning rate во время выполнения алгоритма.

На собеседованиях любят спрашивать про выбор learning rate. В самой простой формулировке вопрос может звучать так: "Как бы вы выбирали learning rate для вашего алгоритма?". Теперь вы знаете ответ.

## Проблема поиска глобального минимума

До этого мы предполагали, что у функции только один минимум. Что будет, если это не так и функция имеет несколько минимумов?

Большинство методов оптимизации работают в предположении, что минимум только один, и говорят, что они находят **локальный минимум**, то есть минимум, ближайший к начальной точке $x_0$.

Поиск глобального минимума - сложная задача, и точного решения она не имеет.

Самое простое что можно сделать - выбрать несколько точек, из каждой запустить градиентный спуск и выбрать ту, где минимум будет меньше. Однако такой метод работал бы долго, а еще функция может оказаться очень простой и мы сделаем лишние вычисления. Что же делать?

## SGD, MiniBatch

Так как мы говорим о задаче оптимизации функций в контексте подбора параметров по каким-то данным, то логично, что чем больше данных мы будем использовать, тем точнее мы посчитаем итоговую функцию, и тем точнее и быстрее (за меньшее количество шагов) мы сможем прийти к минимуму функции. Однако используя обычный градиентный спуск мы придем только к локальному минимуму. А что будет, если мы будем использовать только какой-то кусочек данных? Например, всего один пример?

Сначала кажется, что это очень странная идея, ведь функция ошибки будет посчитана очень неточно. Но если мы проделаем это много раз для разных примеров, то окажется, что общий тренд алгоритма примет то же направление, что и общее при обычном градиентном спуске. Из плюсов - мы сможем "проскочить" некоторые минимумы, которые нас не устраивают. Такой алгоритм называют **стохастическим градиентным спуском** или SGD (stochastic gradient descent).

Чтобы упростить работу алгоритма можно брать не по одному примеру, а сразу выбрать, скажем, 10 примеров, и на них запускать градиентный спуск. Количество примеров будет параметров, который обычно называют **batch size**, а алгоритм называют MiniBatch Gradient Descent.
