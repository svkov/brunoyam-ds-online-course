1. Выберите верные утверждения про обучение случайного леса. ***

- Как правило, строятся деревья небольшой глубины, поскольку этого достаточно для восстановления сложных зависимостей.
- Каждое дерево обучается по случайной подвыборке объектов. **this**
- В каждой вершине оптимальный признак для разбиения выбирается из случайного подмножества признаков.
- Каждое дерево обучается независимо от остальных деревьев в композиции. **this**
- Каждое дерево обучается по случайной подвыборке признаков. **this**

2. Пусть у нас есть выборка из пяти объектов: $[x_1, x_2, x_3, x_4, x_5]$. Отметьте подвыборки, которые могут получиться из неё при использовании бутстрапа.

- $[x_1, x_2, x_2, x_2]$
- $[x_1, x_1, x_1, x_1, x_1]$   **this**
- $[x_3, x_5]$
- $[x_1, x_2, x_2, x_3, x_5]$   **this**
- $[x_1, x_2, x_3, x_4, x_5]$   **this**

3. Какие величины предсказывает $N$-й базовый алгоритм в градиентном бустинге?


- Производные (с минусом) функции потерь, вычисленные в точках, соответствующих ответам предыдущего базового алгоритма $b_{N-1}(x)$ на обучающей выборке.

- Производные (с минусом) функции потерь, вычисленные в точках, соответствующих ответам композиции a_{N-1}(x) на обучающей выборке. **this**

- Разницу между истинными ответами и ответами композиции a_{N-1}(x) на обучающей выборке.


2. В каком пространстве градиентный бустинг осуществляет градиентный спуск?

- В пространстве коэффициентов при базовых алгоритмах.
- В пространстве признаков.
- В пространстве весов при признаках.
- В пространстве прогнозов алгоритма на объектах обучающей выборки. **this**

3. Чем градиентный бустинг отличается от случайного леса? ***

- Каждый следующий алгоритм в градиентном бустинге обучается так, чтобы исправить ошибки предыдущих базовых алгоритмов.  **this**
- Градиентный бустинг может строить алгоритмы только для задач регрессии.
- Базовые алгоритмы, как правило, выбираются достаточно простыми — например, это могут быть неглубокие деревья. **this**

4. Градиент какой функции вычисляется на каждой итерации градиентного бустинга?

- Функции, которая вычисляет ошибку композиции на одном из объектов обучающей выборки.
- Функции, которая вычисляет ошибку композиции на обучающей выборке.    **this**
- Функции, которая вычисляет прогноз композиции в зависимости от признакового описания объекта.

5. Для чего нужно сокращение шага в градиентном бустинге? ***

- Ускорение построения композиции.
- Понижение вклада каждого базового алгоритма в общий прогноз. **this**
- Учёт особенностей функции потерь при построении композиции.
- Борьба с переобучением.   **this**
