# Проблема воспроизводимости вычислений

- Суть проблемы, три класса воспроизводимости результата
- Почему jupyter notebook - не исследование
- Как получить воспроизводимый результат исследования
- Инструменты для построения пайплайнов
- Snakemake
- Airflow
- Luigi

## Введение

Представьте, что вы разрабатываете модель машинного обучения, которая будет решать какую-то реальную задачу. Вы написали код для модели, провели исследование, получили положительные результаты, настало время запустить модель на пользователях. Для того, чтобы это сделать, нужно как-то соединить ваш код модели с веб-приложением, которое доступно пользователям. Как это сделать? Существует два способа.

Первый способ - прямая интеграция с приложением. Код модели буквально встраивается в код приложения и они начинают работать как единое целое. Скорее всего, в результате исследований вы получите модель, которую можно сохранить в файл (например, это будут веса модели), и в коде приложения вы будете читать файл и давать предсказания, этап обучения делается отдельно и в логике приложения обычно не участвует.

Второй способ - вокруг модели пишется простое веб-приложение, которое имеет две функции: получить прогноз модели и обучить модель. Тогда основное приложение будет слать запрос в модель, та будет отдавать ответ и все довольны.

Второй способ более надежен и лучше использовать его. В крупных компаниях есть специальные средства разработки, которые автоматически оборачивают ваш код веб-приложением, и позволяют не задумываться над интеграциями, в компаниях поменьше приходится это делать самостоятельно. Проще всего использовать такие инстурменты как `FastAPI`, `Dash` и `Flask`.

А теперь представьте, что вы запустили приложение на пользователях и стали отслеживать качество модели. Внезапно, результаты становятся сильно хуже, чем ожидалось. Почему так произошло? Скорее всего, отличались условия, которые были в исследовании и которые были на продуктивном сервере. Либо какие-то версии библиотек отличались, либо код был неправильно перенесен, либо данные, на которых проводилось исследование, отличались от реальных. Так или иначе, результат не воспроизвелся. Воспроизводимость вычислений - это очень важно в Data Science, но зачастую ее очень сложно достичь.

Перед тем как двигаться дальше, давайте поймем, что такое вообще воспроизводимость вычислений.

## Виды воспроизводимости вычислений

Воспроизводимость исследования означает, что независимо от внешних факторов мы получим близкие результаты исследования. Для DS это значит, что наше исследование как минимум должно уметь запускаться не только у нас на компьютере. Выделяют три уровня воспроизводимости:

- **Повторяемость измерений** (также сходимость результатов измерений, англ. Repeatability) (Same team, same experimental setup): Результат может быть получен с заявленной точностью при нескольких испытаниях в тех же условиях.
- **Повторяемость исследований** (англ. Replicability) (Different team, same experimental setup): Результат может быть получен с заявленной точностью при нескольких испытаниях в тех же условиях, но другой командой.
- **Воспроизводимость** (англ. Reproducibility): (Different team, different experimental setup): Результат может быть получен независимой группой, используя артефакты, которые они разрабатывают полностью независимо.

Первый уровень самый простой, но даже его не всегда удается получить. Самый простой пример нарушения этого принципа - код в jupyter notebook. Если просто переставить местами ячейки в jupyter или запустить их в другом порядке, то мы получим совсем другой результат, если код вообще запустится. После получения результата надо всегда приводить в порядок код, чтобы в следующий раз получить те же результаты.

Второй уровень получить сложнее. Он предполагает, что любой человек, который будет работать с вашим репозиторием, сможет в этом разобраться и запустить все у себя. Помимо оставленной документации здесь предполагается, что код должен быть хорошо структурирован. Этот код должен запускаться и сегодня и завтра и через пять лет и выдавать схожие результаты.

Третий уровень встречается довольно редко. Его можно встретить, например, когда пишется научная статья по новому подходу для изучения каких-то конкретных данных, где авторы подробно описывают свой подход и предоставляют все данные. Затем другие исследователи берут ту же идею (возможно, куски кода) и применяют ее к другим данным. Если результаты схожие, значит подход действительно воспроизводим и имеет не только практическую, но и научную значимость.

Достичь третьего уровня воспроизводимости довольно сложно, но добиться хотя бы повторяемости исследований реально, если следовать простым правилам.

## Правила воспроизводимости исследований

Правило №1— Для каждого полученного результата сохраните алгоритм его получения.

Важно знать каким образом вы получили те или иные результаты. Знание того, как вы перешли от необработанных данных к заключению, позволяет вам:
защищать результаты
обновлять результаты, если обнаружены ошибки
воспроизводить результаты при обновлении данных
представить свои результаты на обсуждение

Правило №2 - избегайте этапов ручного управления данными или процессом.

Может возникнуть соблазн открыть файлы данных в редакторе и вручную исправить пару ошибок форматирования или удалить выбросы. Кроме того, современные редакторы позволяют легко форматировать файлы огромных размеров. Однако соблазну сократить ваш алгоритм следует сопротивляться. Ручная обработка данных - это скрытая манипуляция.

Правило №3 - сохраните точные версии всех использованных внешних инструментов.

В идеале вы должны настроить виртуальную машину или контейнер со всем программным обеспечением, используемым для запуска ваших скриптов. Это позволяет сделать снимок вашей аналитической экосистемы, что упрощает воспроизведение ваших результатов.
По крайней мере, вам необходимо задокументировать выпуск и версию всего используемого программного обеспечения, включая операционную систему. Незначительные изменения в программном обеспечении могут повлиять на результаты.

Правило №4 - используйте контроль версий.

Для отслеживания версий ваших скриптов следует использовать систему контроля версий, такую ​​как Git. Вы должны пометить (сделать снимок) текущее состояние скриптов и ссылаться на этот тег во всех получаемых вами результатах. Если вы затем решите изменить свои алгоритмы, что вы обязательно сделаете, можно будет вернуться во времени и получить точные сценарии, которые использовались для получения заданного результата.

Правило №5 - храните все промежуточные результаты в стандартизированном виде.

Если вы соблюдаете Правило № 1, в теории уже возможно воссоздать любые результаты на основе необработанных данных. Однако, хотя это может быть теоретически возможно, на практике могут быть ограничивающие факторы.
В этих случаях может быть полезно начать исследование с набора производных данных, которые уже могут представлять больше пользы или быть более удобными, чем необработанных данных. Хранение этих промежуточных наборов данных (например, в формате CSV) предоставляет больше возможностей для дальнейшего анализа и может упростить определение проблемных мест поскольку нет необходимости все переделывать.

Правило №6 - для алгоритмов использующих случайность записывайте их случайное зерно.

Одна вещь, которую специалисты по данным часто не могут сделать - это установить исходные значения для своего анализа. Это делает невозможным точное воссоздание исследований машинного обучения. Многие алгоритмы машинного обучения включают стохастический элемент, и, хотя надежные результаты могут быть статистически воспроизводимыми, гораздо приятнее получать результаты точь-в-точь как в исходном исследовании.

Правило №7 - всегда храните вместе с графиками данные.

Если вы используете скриптовый язык программирования, ваши графики скорее всего генерируются автоматически. Однако, если вы используете такой инструмент, как Excel, убедитесь, что вы сохранили начальные данные. Это позволяет не только воспроизвести график, но также более детально просмотреть лежащие в основе данные.
Также стоит всегда сохранять алгоритмы, которые вы использовали для получения график на основе которых вы потом приводите какие-либо утверждения.

Правило №8 - иерархический подход при генерировании результатов анализа.

Наша задача как специалистов по обработке данных - обобщить данные в той или иной форме. Вот что включает в себя извлечение информации из данных.
Однако резюмирование также является простым способом неправильного использования данных, поэтому важно, чтобы заинтересованные стороны могли разбить сводку на отдельные точки данных. Для каждого итогового результата укажите ссылку на данные, использованные для расчета итогового значения.

Правило №9 - всегда указывайте вместе текстовые утверждения и результаты исследования.

В конце работы результаты анализа данных оформляются в текстовом виде. И слова неточны. Иногда бывает трудно определить связь между выводами и анализом. Поскольку отчет часто является самой важной частью исследования, важно, чтобы его можно было связать с результатами и, в соответствии с правилом № 1, с исходными данными.

Правило №10 - обеспечивайте доступность ваших результатов, данных и исследований.

В коммерческих условиях может быть нецелесообразно предоставлять открытый доступ ко всем данным. Однако имеет смысл предоставить доступ другим пользователям в вашей организации. Облачные системы управления исходным кодом, такие как Bitbucket и GitHub, позволяют создавать частные репозитории, к которым могут получить доступ любые авторизованные коллеги.

- [Кризис машинного обучения в научных исследованиях](https://tproger.ru/translations/machine-learning-crisis)
- [Reproducibility vs. Replicability: A Brief History of a Confused Terminology](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5778115)
- [Repeatability, Reproducibility, and Replicability: Tackling the 3R challenge in biointerface science and engineering](https://avs.scitation.org/doi/full/10.1116/1.5093621)
- [10 RULES FOR CREATING REPRODUCIBLE RESULTS IN DATA SCIENCE](https://dataconomy.com/2017/07/10-rules-results-data-science/)
