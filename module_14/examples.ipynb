{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "778f59f8-9460-4b3f-9288-f423b214daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108836ea-79d8-4bb8-bb25-eef6b512c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Porter:\n",
    "\tPERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "\tREFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "\tADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "\tPARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "\tVERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "\tNOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "\tRVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "\tDERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "\tDER = re.compile(u\"ость?$\")\n",
    "\tSUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "\tI = re.compile(u\"и$\")\n",
    "\tP = re.compile(u\"ь$\")\n",
    "\tNN = re.compile(u\"нн$\")\n",
    "\n",
    "\tdef stem(word):\n",
    "\t\tword = word.lower()\n",
    "\t\tword = word.replace(u'ё', u'е')\n",
    "\t\tm = re.match(Porter.RVRE, word)\n",
    "\t\tif m and m.groups():\n",
    "\t\t\tpre = m.group(1)\n",
    "\t\t\trv = m.group(2)\n",
    "\t\t\ttemp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "\t\t\tif temp == rv:\n",
    "\t\t\t\trv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "\t\t\t\ttemp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "\t\t\t\tif temp != rv:\n",
    "\t\t\t\t\trv = temp\n",
    "\t\t\t\t\trv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttemp = Porter.VERB.sub('', rv, 1)\n",
    "\t\t\t\t\tif temp == rv:\n",
    "\t\t\t\t\t\trv = Porter.NOUN.sub('', rv, 1)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\trv = temp\n",
    "\t\t\telse:\n",
    "\t\t\t\trv = temp\n",
    "\t\t\t\n",
    "\t\t\trv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "\t\t\tif re.match(Porter.DERIVATIONAL, rv):\n",
    "\t\t\t\trv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "\t\t\ttemp = Porter.P.sub('', rv, 1)\n",
    "\t\t\tif temp == rv:\n",
    "\t\t\t\trv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "\t\t\t\trv = Porter.NN.sub(u'н', rv, 1)\n",
    "\t\t\telse:\n",
    "\t\t\t\trv = temp\n",
    "\t\t\tword = pre+rv\n",
    "\t\treturn word\n",
    "\tstem=staticmethod(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f241b9-84d7-43f9-a597-9d8a68100199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 14 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    'Это первый документ.',\n",
    "    'Это второй документ среди всех документов.',\n",
    "    'А вот и третий.',\n",
    "    'Вот и кончились документы.'\n",
    "]\n",
    "bow = CountVectorizer()\n",
    "bow.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0d352b7-20a1-4fb3-96dd-e809c7db6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentence(sentence):\n",
    "    stemmed_words = []\n",
    "    for word in sentence.split():\n",
    "        stemmed_words.append(Porter.stem(word))\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    lower_sentence = sentence.lower()\n",
    "    return re.sub(r'[^\\w\\s]', '', lower_sentence)\n",
    "\n",
    "lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "def lemmatize_sentence(sentence):\n",
    "    lemmatized_words = []\n",
    "    for word in sentence.split():\n",
    "        lemmatized_words.append(lemmatizer.parse(word)[0].normal_form)\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "def preprocess_sentence_lemmatize(sentence):\n",
    "    return lemmatize_sentence(remove_punctuation(sentence))\n",
    "\n",
    "def preprocess_sentence_stem(sentence):\n",
    "    return stem_sentence(remove_punctuation(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2320106a-a4e8-44bc-befd-a69ecfa47b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b878c67a-c05c-49be-b345-5b486ac355a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это первый документ\n",
      "это второй документ среди весь документ\n",
      "а вот и третий\n",
      "вот и кончиться документ\n"
     ]
    }
   ],
   "source": [
    "for text in documents:\n",
    "    print(preprocess_sentence_lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c2a9c7b-bc01-4db5-8c79-04ce86fe1709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\koval\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3d03f18-e274-4514-8893-7c5d5d07195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "russian_stopwords = set(russian_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6dcee63e-3116-46b3-97f3-2f577bea35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentence):\n",
    "    filtered_words = []\n",
    "    for word in sentence.split():\n",
    "        if word not in russian_stopwords:\n",
    "            filtered_words.append(word)\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83890af0-a78b-416a-b914-6685be305667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'документы мои любимые документы задокументились'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('документы мои любимые документы и вы задокументились')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b24c084a-de46-46a7-9065-5dbc9336e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence_lemmatize(sentence):\n",
    "    return lemmatize_sentence(remove_stopwords(remove_punctuation(sentence)))\n",
    "\n",
    "def preprocess_sentence_stem(sentence):\n",
    "    return stem_sentence(remove_stopwords(remove_punctuation(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e4d3693-54f1-4722-a727-ded6a04bbe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это первый документ\n",
      "это второй документ среди документ\n",
      "третий\n",
      "кончиться документ\n"
     ]
    }
   ],
   "source": [
    "for text in documents:\n",
    "    print(preprocess_sentence_lemmatize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62533a96-1e7c-40f3-ba19-4fc1e4482be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
