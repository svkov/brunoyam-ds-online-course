# Сложность алгоритмов

Одну и ту же задачу можно решить разными способами. Например, давайте представим, что нам нужно посчитать сумму целых чисел от a до b. Мы можем написать простой код и при помощи цикла посчитать сумму:

```python
a = 1
b = 10000
s = 0
for i in range(a, b):
    s += i
print(s)
```

Можно вспомнить про то, что для вычисления этого же значения можно воспользоваться суммой арифметической прогрессии:

```python
n = b - a
s = (a + b) * n / 2
```

В каком случае компьютер сделает меньше операций? Конечно, во втором. Сложить и перемножить несколько чисел проще, чем сделать несколько тысяч итераций цикла. А можно ли как-то измерить количество операций, которое будет необходимо алгоритму? Для этого используют понятие **сложности алгоритма**.

## Трудоемкость и сложность алгоритма

Начнем с более простого понятие - трудоемкость алгоритма.

**Трудоемкость алгоритма** - это количество элементарных операций, которые сделает алгоритм от своего старта и до завершения. Элементарная операция - это, например, сложение, умножение, вывод на экран, присвоение и т.д. Обычно трудоемкость обозначают $F(N)$, где $N$ - количество входных данных. Например, рассмотрим такой код:

```python
N = 100
for i in range(N):
    print(i)
```

Трудоемкость этого алгоритма будет составлять $F(N) = 2N + 1$. На каждом шаге цикла в переменную i присваивается новое значение и печатается, то есть на каждой итерации цикла происходит 2 элементарные операции. До цикла присваивается значение в переменную N, это еще одна операция. Если мы изменим значение N, то поменяется количество операций цикла и изменится трудоемкость.

Трудоемкость - очень понятная величина. Чем быстрее будет расти функция, тем сложнее будет алгоритм. Например, алгоритм со сложностью $F(N) = N^2 + 5N + 9$ будет намного сложнее, чем рассмотренный выше. Алгоритм с такой сложностью можно получить, если написать два вложенных цикла, и тогда на каждой итерации первого цикла будет проходить полный второй цикл.

Для того, чтобы более объективно сравнивать между собой скорость работы алгоритма, обычно смотрят насколько быстро будет расти скорость работы алгоритма. Например, если какой-то алгоритм при N=10 отработал за 10 секунд, а при N=100 отработал за 100 секунд, то говорят, что у него **линейная сложность** и обозначают $O(N)$. На самом деле, совсем не важно за сколько времени реально отработает алгоритм. Здесь важно то, что скорее всего в трудоемкости алгоритма наибольший вклад вносит линейный член. Если бы скорость работы алгоритма увеличилась не в 10 раз, а в 100 раз, то мы бы говорили о **квадратичной сложности**, которую обозначают $O(N^2)$. Обозначение $O(F)$  говорит о том, что мы смотрим только на тот член функции, который вносит основной вклад в рост. Нам важно не абсолютное количество операций, которое нужно сделать для того, чтобы алгоритм исполнился, а то, насколько быстро будет увеличиваться это количество операций.

Например, если есть алгоритм с трудоемкостью $1000000N$, то его сложность все равно будет $O(N)$, и на небольших значениях он будет работать медленнее, чем алгоритм со сложностью $O(N^2)$, но после какого-то большого $N$, он начнет работать быстрее.

## Какие бывают сложности алгоритмов

Будем рассматривать сложности в порядке увеличения.

### Константа

$O(1)$

Самый "быстрый" алгоритм - это алгоритм, у которого мы заранее знаем время исполнения. Например, если в программе нет циклов и рекурсивных вызовов функций, то он будет выполняться за константное время. Однако если такой алгоритм будет очень большим (на тысячи строк кода), то он может проиграть простому линейному алгоритму в скорости.

Пример: подсчет суммы чисел при помощи формулы суммы арифметической прогрессии

### Логарифм

$O(log\ n)$

Логарифмические алгоритмы тоже обычно очень быстрые. Трудоемкость практически не увеличивается при увеличении входных данных.

Пример: бинарный поиск, поиск или запись в словаре и множестве (set).

### Линейное время

$O(n)$

Линейные алгоритмы (еще говорят "исполняется за "линию"") средние по скорости. Если мы проходим весь список, то это будет линейная сложность. Если мы хотим посчитать сумму элементов списка, или найти минимум/максимум, то это также будет линейная сложность. Такие алгоритмы часто встречаются и если никак не получается избежать всего обхода коллекции, то нужно стараться привести алгоритм хотя бы к линейному времени. Обычно это программы с одним или несколькими не вложенными циклами for. В то же время, если вернуться к первому примеру из этого урока про сумму чисел от a до b, то в нем можно избежать линейного времени и заменить его на константное.

Пример: поиск минимума/максимума в массиве, вывод массива на экран, подсчет суммы чисел без формулы арифметической прогрессии.

### "Эн-лог-эн"

$O(n\ log\ n)$

Алгоритм такой сложности немного сложнее, чем линейные алгоритмы (совсем немного, правда). Почти все хорошие алгоритмы сортировки работают за такое время в среднем. Если в вашей задаче встречается обязательный шаг сортировки, то вы точно столкнетесь как минимум с такой сложностью.

Пример: хорошие алгоритмы сортировки в среднем случае.

### Квадратичная сложность

$O(n^2)$

Начинаются медленные алгоритмы. За квадратичное время можно, например, сложить две квадратные матрицы размером (n, n). Также за квадратичное время можно отсортировать любой массив. Квадратичная сложность - худшая сложность для любого хорошего алгоритма сортировки и обычная сложность для простых алгоритмов сортировки (например, пузырьковая сортировка или сортировка вставками). Если вы не работаете с матрицами, то старайтесь избегать такой сложности, потому что это может быть достаточно долго.

Пример: плохие алгоритмы сортировки, операции над матрицами

### Полиномиальная сложность

$O(n^p)$

При p=2 получаем квадратичную сложность, поэтому все, что будет написано ниже, относится и к этим алгоритмам. Полиномиальные алгоритмы - это алгоритмы, для которых можно писать эффективные программы. Например, базовый алгоритм умножения матриц имеет сложность $O(n^3)$, но его можно ускорить примерно до $O(n^{2.37})$, что бывает очень эффективно для больших матриц. Также если мы посмотрим на реализацию операций сложения, умножения и квадратного корня для больших чисел, то у них также будет полиномиальная сложность. Полиномиальные алгоритмы медленные, но их все еще можно применять для разумных n. Класс задач, которые решаются полиномиальными алгоритмами, иногда выделяют и обозначают P.

Пример: умножение матриц, решение систем линейных уравнений, арифметические операции

### Экспоненциальные алгоритмы

$O(2^n), O(n!), O(2^{2^n})$

Если у вас встретилась такая сложность, то вы решаете задачу полным перебором. Эти алгоритмы очень медленные, но иногда мы вынуждены их использовать. Например, если мы хотим найти все возможные пути из точки A в точку B на карте, то мы будем вынуждены использовать такой алгоритм. Также такие алгоритмы часто встречаются в задачах оптимизации, построении расписаний, комбинаторике, криптографии и многих других областях. Есть целый класс задач (NP-сложные задачи), который не решается быстрее, чем за экспоненциальное время. Существует гипотеза о том, что класс NP на самом деле равен классу P. Если кто-то докажет это и появятся полиномиальные алгоритмы для известных NP-сложных задач, то мы сможем намного эффективнее решать повседневные задачи. Эта гипотеза входит в [список задач тысячелетия](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B8_%D1%82%D1%8B%D1%81%D1%8F%D1%87%D0%B5%D0%BB%D0%B5%D1%82%D0%B8%D1%8F) и за ее решение назначена награда в один миллион долларов.

## Итоги

От сложности алгоритма зависит насколько быстро будет увеличиваться время исполнения алгоритма. Ниже сравнительная таблица для некоторых сложностей:

![complexity](https://media.tproger.ru/uploads/2017/09/complexity-table.png)

Важно помнить, что сложность - не равно время исполнения, но одно влияет на другое. Помимо скорости выполнения, таким же способом подсчитывают количество памяти, необходимое алгоритму.

Знание сложности различных алгоритмов и умение оценивать сложность - это ключевой навык любого человека, который имеет отношение к программированию. Крупные компании зачастую проводят алгоритмические собеседования, чтобы проверить знания алгоритмов и умение составлять код, который решает задачи. Вы можете самостоятельно попрактиковаться в составлении алгоритмов на одном из сайтов:

- [Leetcode](https://leetcode.com/)
- [Hackerrank](https://www.hackerrank.com/)
- [Codeforces](https://codeforces.com/)

Для аналитика данных это особенно важная компетенция, так как нам приходится работать с большими объемами данных и если мы составим неоптимальный алгоритм, то будем очень долго ждать, пока все посчитается. Зачастую простое изменение в коде сокращает расчеты с недель до считанных минут. Сейчас компьютеры достаточно мощные и если для задачи, которая предполагает небольшие входные данные, можно написать неоптимальный код и забыть про это, то для больших данных такой подход точно не подойдет. Прежде чем запрашивать больше мощностей для вычислений, стоит спросить себя - могу ли я что-то изменить в коде, чтобы он работал быстрее?
